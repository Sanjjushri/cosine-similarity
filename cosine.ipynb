{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f8bed-3119-4825-b609-16bc1df08414",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pdfplumber \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98257922-43c2-4567-a967-524caac8a1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text preview: I am Sanjjushri\n",
      "I love apple\n",
      "I am an Entrepreneur\n",
      "I am a Millionaire\n",
      "I am a Youtuber\n",
      "I love waterfalls \n",
      "Extracted sentences: ['I am Sanjjushri', 'I love apple', 'I am an Entrepreneur', 'I am a Millionaire', 'I am a Youtuber', 'I love waterfalls']\n",
      "Vector shape: (7, 9)\n",
      "Number of sentences: 6\n",
      "Length of target_vector: 7\n",
      "\n",
      "Sentences with similarity >= 80%:\n",
      "Sentence: I am Sanjjushri\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Extract text from the PDF using pdfplumber\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Check if text was extracted from the page\n",
    "                pdf_text += page_text + \" \"\n",
    "    return pdf_text\n",
    "\n",
    "# Step 2: Split the text into sentences\n",
    "def split_into_sentences(text):\n",
    "    # Split the text on sentence-ending punctuation and newline characters\n",
    "    sentences = re.split(r'(?<=[.!?]) +|\\n+', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "# Step 3: Find similar sentences using cosine similarity\n",
    "def find_similar_statements(target_statement, sentences, threshold_80=0.8):\n",
    "    # Fit and transform the target and all sentences into TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer().fit_transform([target_statement] + sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    target_vector = cosine_matrix[0]  # First row corresponds to the target statement\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"Vector shape: {vectors.shape}\")\n",
    "    print(f\"Number of sentences: {len(sentences)}\")\n",
    "    print(f\"Length of target_vector: {len(target_vector)}\")\n",
    "\n",
    "    # Ensure alignment between target_vector and sentences\n",
    "    if len(target_vector) - 1 > len(sentences):\n",
    "        raise ValueError(\"Vector size mismatch: target_vector contains more elements than sentences.\")\n",
    "\n",
    "    # Filter sentences based on similarity thresholds (80% or higher)\n",
    "    similar_sentences_80 = [\n",
    "        sentences[i - 1]  # Adjust indexing to align with sentences\n",
    "        for i, score in enumerate(target_vector[1:], 1)\n",
    "        if i - 1 < len(sentences) and score >= threshold_80\n",
    "    ]\n",
    "\n",
    "    return similar_sentences_80\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/sanjju/Downloads/test.pdf'\n",
    "target = \"Sanjjushri\"\n",
    "\n",
    "# Step 4: Extract, split, and find similar sentences\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(\"Extracted text preview:\", text[:500])  # Debugging step\n",
    "\n",
    "if not text.strip():\n",
    "    raise ValueError(\"No text extracted from the PDF. Please check the PDF content or format.\")\n",
    "\n",
    "sentences = split_into_sentences(text)\n",
    "print(\"Extracted sentences:\", sentences)  # Debugging step\n",
    "\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No sentences were found in the extracted text.\")\n",
    "\n",
    "# Find similar sentences and filter by similarity thresholds\n",
    "similar_sentences_80 = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print and store sentences with similarity >= 80%\n",
    "if similar_sentences_80:\n",
    "    print(\"\\nSentences with similarity >= 80%:\")\n",
    "    for sentence in similar_sentences_80:\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"\\nNo sentences with 80% similarity or higher.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "500e8a95-7b99-43c7-a6d9-93b47786e2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Sanjjushri']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_sentences_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f56b04-37d0-4932-a985-61755148c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed0634-0568-469e-8535-178fa7cdd2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2de7725-d921-4f12-b982-2991b61ab9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text preview: I am Sanjjushri\n",
      "I love apple\n",
      "I am an Entrepreneur\n",
      "I am a Millionaire\n",
      "I am a Youtuber\n",
      "I love waterfalls \n",
      "Extracted sentences: ['I am Sanjjushri', 'I love apple', 'I am an Entrepreneur', 'I am a Millionaire', 'I am a Youtuber', 'I love waterfalls']\n",
      "Vector shape: (7, 9)\n",
      "Number of sentences: 6\n",
      "Length of target_vector: 7\n",
      "\n",
      "Sentences with similarity >= 70%:\n",
      "Similarity: 0.80 - Sentence: I am Sanjjushri\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Extract text from the PDF using pdfplumber\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Check if text was extracted from the page\n",
    "                pdf_text += page_text + \" \"\n",
    "    return pdf_text\n",
    "\n",
    "# Step 2: Split the text into sentences\n",
    "def split_into_sentences(text):\n",
    "    # Split the text on sentence-ending punctuation and newline characters\n",
    "    sentences = re.split(r'(?<=[.!?]) +|\\n+', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "# Step 3: Find similar sentences using cosine similarity\n",
    "def find_similar_statements(target_statement, sentences, threshold_70=0.7):\n",
    "    # Fit and transform the target and all sentences into TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer().fit_transform([target_statement] + sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    target_vector = cosine_matrix[0]  # First row corresponds to the target statement\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"Vector shape: {vectors.shape}\")\n",
    "    print(f\"Number of sentences: {len(sentences)}\")\n",
    "    print(f\"Length of target_vector: {len(target_vector)}\")\n",
    "\n",
    "    # Ensure alignment between target_vector and sentences\n",
    "    if len(target_vector) - 1 > len(sentences):\n",
    "        raise ValueError(\"Vector size mismatch: target_vector contains more elements than sentences.\")\n",
    "\n",
    "    # Filter sentences based on similarity thresholds\n",
    "    similar_sentences_70 = [\n",
    "        (sentences[i - 1], score)  # Adjust indexing to align with sentences\n",
    "        for i, score in enumerate(target_vector[1:], 1)\n",
    "        if i - 1 < len(sentences) and score >= threshold_70\n",
    "    ]\n",
    "\n",
    "    # similar_sentences_80 = [\n",
    "    #     (sentences[i - 1], score)  # Adjust indexing to align with sentences\n",
    "    #     for i, score in enumerate(target_vector[1:], 1)\n",
    "    #     if i - 1 < len(sentences) and score >= threshold_80\n",
    "    # ]\n",
    "\n",
    "    return similar_sentences_70\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/sanjju/Downloads/test.pdf'\n",
    "target = \"Sanjjushri\"\n",
    "\n",
    "# Step 4: Extract, split, and find similar sentences\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(\"Extracted text preview:\", text[:500])  # Debugging step\n",
    "\n",
    "if not text.strip():\n",
    "    raise ValueError(\"No text extracted from the PDF. Please check the PDF content or format.\")\n",
    "\n",
    "sentences = split_into_sentences(text)\n",
    "print(\"Extracted sentences:\", sentences)  # Debugging step\n",
    "\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No sentences were found in the extracted text.\")\n",
    "\n",
    "# Find similar sentences and filter by similarity thresholds\n",
    "similar_sentences_70 = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print and store sentences with similarity >= 70%\n",
    "if similar_sentences_70:\n",
    "    print(\"\\nSentences with similarity >= 70%:\")\n",
    "    for sentence, similarity in similar_sentences_70:\n",
    "        print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"\\nNo sentences with 70% similarity or higher.\")\n",
    "\n",
    "# Print and store sentences with similarity >= 80%\n",
    "# if similar_sentences_80:\n",
    "#     print(\"\\nSentences with similarity >= 80%:\")\n",
    "#     for sentence, similarity in similar_sentences_80:\n",
    "#         print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "# else:\n",
    "#     print(\"\\nNo sentences with 80% similarity or higher.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf39797-ff68-429e-9cc5-280eb9afb866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I am Sanjjushri', 0.803028938037097)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_sentences_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575f99c-d065-43f8-9b9a-3c2b74bbf96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce06dc4-b274-42a8-9184-53e55a0085bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5af395-97d1-4198-9cf2-68c5e0c01f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a93a0a8-d8b6-4fed-9b49-5ea6f71e0c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text preview: I am Sanjjushri\n",
      "I love apple\n",
      "I am an Entrepreneur\n",
      "I am a Millionaire\n",
      "I am a Youtuber\n",
      "I love waterfalls \n",
      "Extracted sentences: ['I am Sanjjushri', 'I love apple', 'I am an Entrepreneur', 'I am a Millionaire', 'I am a Youtuber', 'I love waterfalls']\n",
      "Vector shape: (7, 9)\n",
      "Number of sentences: 6\n",
      "Length of target_vector: 7\n",
      "Sentences with similarity >= 70%:\n",
      "Similarity: 0.80 - Sentence: I am Sanjjushri\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Extract text from the PDF using pdfplumber\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Check if text was extracted from the page\n",
    "                pdf_text += page_text + \" \"\n",
    "    return pdf_text\n",
    "\n",
    "# Step 2: Split the text into sentences\n",
    "def split_into_sentences(text):\n",
    "    # Split the text on sentence-ending punctuation and newline characters\n",
    "    sentences = re.split(r'(?<=[.!?]) +|\\n+', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "# Step 3: Find similar sentences using cosine similarity\n",
    "def find_similar_statements(target_statement, sentences, threshold=0.7):\n",
    "    # Fit and transform the target and all sentences into TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer().fit_transform([target_statement] + sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    target_vector = cosine_matrix[0]  # First row corresponds to the target statement\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"Vector shape: {vectors.shape}\")\n",
    "    print(f\"Number of sentences: {len(sentences)}\")\n",
    "    print(f\"Length of target_vector: {len(target_vector)}\")\n",
    "\n",
    "    # Ensure alignment between target_vector and sentences\n",
    "    if len(target_vector) - 1 > len(sentences):\n",
    "        raise ValueError(\"Vector size mismatch: target_vector contains more elements than sentences.\")\n",
    "\n",
    "    # Filter sentences with cosine similarity >= 0.7\n",
    "    similar_sentences = [\n",
    "        (sentences[i - 1], score)  # Adjust indexing to align with sentences\n",
    "        for i, score in enumerate(target_vector[1:], 1)\n",
    "        if i - 1 < len(sentences) and score >= threshold\n",
    "    ]\n",
    "\n",
    "    return similar_sentences\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/sanjju/Downloads/test.pdf'\n",
    "target = \"Sanjjushri\"\n",
    "\n",
    "# Step 4: Extract, split, and find similar sentences\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(\"Extracted text preview:\", text[:500])  # Debugging step\n",
    "\n",
    "if not text.strip():\n",
    "    raise ValueError(\"No text extracted from the PDF. Please check the PDF content or format.\")\n",
    "\n",
    "sentences = split_into_sentences(text)\n",
    "print(\"Extracted sentences:\", sentences)  # Debugging step\n",
    "\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No sentences were found in the extracted text.\")\n",
    "\n",
    "# Find similar sentences and filter by similarity threshold\n",
    "similar_sentences = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print and store sentences with similarity >= 70%\n",
    "if similar_sentences:\n",
    "    print(\"Sentences with similarity >= 70%:\")\n",
    "    for sentence, similarity in similar_sentences:\n",
    "        print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"No sentences with 70% similarity or higher.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2937edfa-13f6-4bd5-899a-8fafd7feea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I am Sanjjushri', 0.803028938037097)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6049203-6250-4742-aecf-e791a6ac783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape: (7, 13)\n",
      "Number of sentences: 6\n",
      "Length of target_vector: 7\n",
      "Similarity: 0.00 - Sentence: I am Sanjjushri\n",
      "Similarity: 0.00 - Sentence: I love apple\n",
      "Similarity: 0.00 - Sentence: I am an Entrepreneur\n",
      "Similarity: 0.00 - Sentence: I am a Millionaire\n",
      "Similarity: 0.00 - Sentence: I am a Youtuber\n",
      "Vector shape: (7, 13)\n",
      "Number of sentences: 6\n",
      "Length of target_vector: 7\n",
      "Similarity: 0.00 - Sentence: I am Sanjjushri\n",
      "Similarity: 0.00 - Sentence: I love apple\n",
      "Similarity: 0.00 - Sentence: I am an Entrepreneur\n",
      "Similarity: 0.00 - Sentence: I am a Millionaire\n",
      "Similarity: 0.00 - Sentence: I am a Youtuber\n",
      "Extracted text preview: I am Sanjjushri\n",
      "I love apple\n",
      "I am an Entrepreneur\n",
      "I am a Millionaire\n",
      "I am a Youtuber\n",
      "I love waterfalls \n",
      "Extracted sentences: ['I am Sanjjushri', 'I love apple', 'I am an Entrepreneur', 'I am a Millionaire', 'I am a Youtuber', 'I love waterfalls']\n",
      "Vector shape: (7, 9)\n",
      "Number of sentences: 6\n",
      "Length of target_vector: 7\n",
      "Similarity: 0.80 - Sentence: I am Sanjjushri\n",
      "Similarity: 0.00 - Sentence: I love apple\n",
      "Similarity: 0.00 - Sentence: I am an Entrepreneur\n",
      "Similarity: 0.00 - Sentence: I am a Millionaire\n",
      "Similarity: 0.00 - Sentence: I am a Youtuber\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Extract text from the PDF using pdfplumber\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Check if text was extracted from the page\n",
    "                pdf_text += page_text + \" \"\n",
    "    return pdf_text\n",
    "\n",
    "# Step 2: Split the text into sentences\n",
    "def split_into_sentences(text):\n",
    "    # Split the text on sentence-ending punctuation and newline characters\n",
    "    sentences = re.split(r'(?<=[.!?]) +|\\n+', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "# Step 3: Find similar sentences using cosine similarity\n",
    "def find_similar_statements(target_statement, sentences):\n",
    "    # Fit and transform the target and all sentences into TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer().fit_transform([target_statement] + sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    target_vector = cosine_matrix[0]  # First row corresponds to the target statement\n",
    "\n",
    "    # Debugging output\n",
    "    print(f\"Vector shape: {vectors.shape}\")\n",
    "    print(f\"Number of sentences: {len(sentences)}\")\n",
    "    print(f\"Length of target_vector: {len(target_vector)}\")\n",
    "\n",
    "    # Ensure alignment between target_vector and sentences\n",
    "    if len(target_vector) - 1 > len(sentences):\n",
    "        raise ValueError(\"Vector size mismatch: target_vector contains more elements than sentences.\")\n",
    "\n",
    "    # Rank sentences by similarity\n",
    "    similar_sentences = [\n",
    "        (sentences[i - 1], score)  # Adjust indexing to align with sentences\n",
    "        for i, score in enumerate(target_vector[1:], 1)\n",
    "        if i - 1 < len(sentences)\n",
    "    ]\n",
    "\n",
    "    return sorted(similar_sentences, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Run the function and check for issues\n",
    "results = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print top 5 most similar sentences\n",
    "if results:\n",
    "    for sentence, similarity in results[:5]:\n",
    "        print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"No similar sentences found.\")\n",
    "\n",
    "\n",
    "# Run the function and check for issues\n",
    "results = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print top 5 most similar sentences\n",
    "if results:\n",
    "    for sentence, similarity in results[:5]:\n",
    "        print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"No similar sentences found.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/sanjju/Downloads/test.pdf'\n",
    "target = \"Sanjjushri\"\n",
    "\n",
    "# Step 4: Extract, split, and find similar sentences\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(\"Extracted text preview:\", text[:500])  # Debugging step\n",
    "\n",
    "if not text.strip():\n",
    "    raise ValueError(\"No text extracted from the PDF. Please check the PDF content or format.\")\n",
    "\n",
    "sentences = split_into_sentences(text)\n",
    "print(\"Extracted sentences:\", sentences)  # Debugging step\n",
    "\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No sentences were found in the extracted text.\")\n",
    "\n",
    "results = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print top 5 most similar sentences\n",
    "if results:\n",
    "    for sentence, similarity in results[:5]:\n",
    "        print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"No similar sentences found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00788a7-4f71-41b8-9d32-c2473543dc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec3e06-3ca8-4ec1-867d-9a29265bef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b292f0-3111-40e9-bf3b-632b7370e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text_from_pdf(pdf_path)\n",
    "if not text.strip():\n",
    "    raise ValueError(\"No text extracted from the PDF. Please check the PDF content or format.\")\n",
    "\n",
    "sentences = split_into_sentences(text)\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"No sentences were found in the extracted text.\")\n",
    "\n",
    "results = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print top 5 most similar sentences\n",
    "if results:\n",
    "    for sentence, similarity in results[:5]:\n",
    "        print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "else:\n",
    "    print(\"No similar sentences found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f91e77-9378-4542-b688-0fcc2e7d41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_text = \"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:  # Check if text was extracted\n",
    "                pdf_text += page_text + \" \"\n",
    "    return pdf_text\n",
    "\n",
    "# Step 2: Split the text into sentences\n",
    "def split_into_sentences(text):\n",
    "    if not text.strip():  # Check if the text is empty or whitespace\n",
    "        return []\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    return sentences\n",
    "\n",
    "# Step 3: Find similar sentences using cosine similarity\n",
    "def find_similar_statements(target_statement, sentences):\n",
    "    if not sentences:\n",
    "        print(\"No sentences found in the PDF.\")\n",
    "        return []\n",
    "    \n",
    "    vectorizer = TfidfVectorizer().fit_transform([target_statement] + sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    target_vector = cosine_matrix[0]  # First row corresponds to the target statement\n",
    "\n",
    "    # Rank sentences by similarity (skip the first as it is the target itself)\n",
    "    similar_sentences = sorted(\n",
    "        enumerate(target_vector[1:], 1), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    return [(sentences[i], score) for i, score in similar_sentences]\n",
    "\n",
    "# Example usage\n",
    "pdf_path = 'path/to/your/pdf_file.pdf'\n",
    "target = 'Your target statement to compare against.'\n",
    "\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "if not text:\n",
    "    print(\"Failed to extract text from the PDF.\")\n",
    "else:\n",
    "    sentences = split_into_sentences(text)\n",
    "    results = find_similar_statements(target, sentences)\n",
    "\n",
    "    # Print top 5 most similar sentences\n",
    "    if results:\n",
    "        for sentence, similarity in results[:5]:\n",
    "            print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n",
    "    else:\n",
    "        print(\"No similar statements found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9c99b-bf08-4f60-9fe9-0dc633003a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_text = \"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            pdf_text += page.extract_text() + \" \"\n",
    "    return pdf_text\n",
    "\n",
    "# Step 2: Split the text into sentences\n",
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    return sentences\n",
    "\n",
    "# Step 3: Find similar sentences using cosine similarity\n",
    "def find_similar_statements(target_statement, sentences):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([target_statement] + sentences)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    target_vector = cosine_matrix[0]  # First row corresponds to the target statement\n",
    "\n",
    "    # Rank sentences by similarity (skip the first as it is the target itself)\n",
    "    similar_sentences = sorted(\n",
    "        enumerate(target_vector[1:], 1), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    return [(sentences[i], score) for i, score in similar_sentences]\n",
    "\n",
    "# Example usage\n",
    "pdf_path = 'path/to/your/pdf_file.pdf'\n",
    "target = 'Your target statement to compare against.'\n",
    "\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "sentences = split_into_sentences(text)\n",
    "results = find_similar_statements(target, sentences)\n",
    "\n",
    "# Print top 5 most similar sentences\n",
    "for sentence, similarity in results[:5]:\n",
    "    print(f\"Similarity: {similarity:.2f} - Sentence: {sentence}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
